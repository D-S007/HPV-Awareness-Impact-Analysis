{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Purpose**: To perform statistical tests to evaluate intervention effectiveness and generate a comprehensive report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 : Importing Libraries and Configuration Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pingouin as pg\n",
    "from docx import Document\n",
    "import statsmodels.stats.power as smp\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename='../logs/stat_analysis.log', level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "print('Libraries imported successfully.')\n",
    "logging.info('Libraries imported successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Loading data\n",
    "df_final = pd.read_csv('../data/processed_data/cleaned_hpv_data.csv')\n",
    "df_pre_full = pd.read_excel('../data/processed_data/summary_data.xlsx', sheet_name='pretest')\n",
    "df_post_full = pd.read_excel('../data/processed_data/summary_data.xlsx', sheet_name='post_test')\n",
    "print('Data loaded successfully.')\n",
    "logging.info('Data loaded successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 : Reliability Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Cronbach's Alpha for survey reliability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cronbach's Alpha (Pre-Test): 0.858\n",
      "Cronbach's Alpha (Post-Test): 0.736\n"
     ]
    }
   ],
   "source": [
    "question_cols = [str(i) for i in range(1, 34)]\n",
    "alpha_pre = pg.cronbach_alpha(data=df_pre_full[question_cols])[0]\n",
    "alpha_post = pg.cronbach_alpha(data=df_post_full[question_cols])[0]\n",
    "print(f'Cronbach\\'s Alpha (Pre-Test): {alpha_pre:.3f}')\n",
    "print(f'Cronbach\\'s Alpha (Post-Test): {alpha_post:.3f}')\n",
    "logging.info(f'Cronbach\\'s Alpha - Pre: {alpha_pre:.3f}, Post: {alpha_post:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Normality Check and Intervention Effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Test Normality: p=0.024 (normal if >0.05)\n",
      "Post-Test Normality: p=0.819\n"
     ]
    }
   ],
   "source": [
    "# Normality check\n",
    "stat_pre, p_pre = stats.shapiro(df_final['pre_test_score'])\n",
    "stat_post, p_post = stats.shapiro(df_final['post_test_score'])\n",
    "print(f'Pre-Test Normality: p={p_pre:.3f} (normal if >0.05)')\n",
    "print(f'Post-Test Normality: p={p_post:.3f}')\n",
    "logging.info(f'Normality - Pre: p={p_pre:.3f}, Post: p={p_post:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paired T-Test: t=6.995, p=0.000\n"
     ]
    }
   ],
   "source": [
    "# Paired T-test\n",
    "t_stat, p_val_t = stats.ttest_rel(df_final['post_test_score'], df_final['pre_test_score'])\n",
    "print(f'Paired T-Test: t={t_stat:.3f}, p={p_val_t:.3f}')\n",
    "logging.info(f'Paired T-Test: t={t_stat:.3f}, p={p_val_t:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wilcoxon Signed-Rank Test: statistic=151.000, p=0.000\n"
     ]
    }
   ],
   "source": [
    "# Wilcoxon Signed-Rank Test (non-parametric alternative)\n",
    "w_stat, p_val_w = stats.wilcoxon(df_final['post_test_score'], df_final['pre_test_score'])\n",
    "print(f'Wilcoxon Signed-Rank Test: statistic={w_stat:.3f}, p={p_val_w:.3f}')\n",
    "logging.info(f'Wilcoxon Test: statistic={w_stat:.3f}, p={p_val_w:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's d: 1.28 (large effect if >0.8)\n"
     ]
    }
   ],
   "source": [
    "# Effect size (Cohen's d)\n",
    "eff_size = pg.compute_effsize(df_final['post_test_score'], df_final['pre_test_score'], paired=True)\n",
    "print(f'Cohen\\'s d: {eff_size:.2f} (large effect if >0.8)')\n",
    "logging.info(f'Cohen\\'s d: {eff_size:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Power: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Power analysis\n",
    "power = smp.TTestIndPower().power(effect_size=eff_size, nobs1=len(df_final), alpha=0.05, ratio=1.0)\n",
    "print(f'Statistical Power: {power:.3f}')\n",
    "logging.info(f'Statistical Power: {power:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3 : Demographic Group Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score improvement by education level (ANOVA with Bonferroni correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANOVA (Education): F=1.118, p=0.334, Corrected p=1.000\n"
     ]
    }
   ],
   "source": [
    "edu_groups = [df_final[df_final['Education_Label'] == edu]['score_improvement'] for edu in df_final['Education_Label'].unique()]\n",
    "f_stat, p_val_anova = stats.f_oneway(*edu_groups)\n",
    "p_vals = [p_val_t, p_val_w, p_val_anova]\n",
    "reject, p_vals_corrected, _, _ = multipletests(p_vals, alpha=0.05, method='bonferroni')\n",
    "print(f'ANOVA (Education): F={f_stat:.3f}, p={p_val_anova:.3f}, Corrected p={p_vals_corrected[2]:.3f}')\n",
    "logging.info(f'ANOVA (Education): F={f_stat:.3f}, p={p_val_anova:.3f}, Corrected p={p_vals_corrected[2]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4 : Saving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved stats_results.pkl in models/\n"
     ]
    }
   ],
   "source": [
    "import pickle, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "PROC_DIR = Path(\"../models\")\n",
    "\n",
    "# --- Organize results into dict ---\n",
    "stats_results = {\n",
    "    \"cronbach\": {\n",
    "        \"alpha_pre\": float(alpha_pre),\n",
    "        \"alpha_post\": float(alpha_post)\n",
    "    },\n",
    "    \"normality\": {\n",
    "        \"pre\": {\"stat\": float(stat_pre), \"p\": float(p_pre)},\n",
    "        \"post\": {\"stat\": float(stat_post), \"p\": float(p_post)}\n",
    "    },\n",
    "    \"paired_tests\": {\n",
    "        \"t_test\": {\"t\": float(t_stat), \"p\": float(p_val_t)},\n",
    "        \"wilcoxon\": {\"W\": float(w_stat), \"p\": float(p_val_w)},\n",
    "        \"cohens_d\": float(eff_size),\n",
    "        \"power\": float(power)\n",
    "    },\n",
    "    \"anova\": {\n",
    "        \"education\": {\"F\": float(f_stat), \"p\": float(p_val_anova), \"p_corr\": float(p_vals_corrected[2])}\n",
    "    }\n",
    "}\n",
    "\n",
    "# --- Create summary DataFrame ---\n",
    "results_table = pd.DataFrame([\n",
    "    [\"Shapiro (Pre)\", stat_pre, p_pre, \"★\" if p_pre<0.05 else \"•\"],\n",
    "    [\"Shapiro (Post)\", stat_post, p_post, \"★\" if p_post<0.05 else \"•\"],\n",
    "    [\"Paired t-test\", t_stat, p_val_t, \"★\" if p_val_t<0.05 else \"•\"],\n",
    "    [\"Wilcoxon\", w_stat, p_val_w, \"★\" if p_val_w<0.05 else \"•\"],\n",
    "    [\"ANOVA (Education)\", f_stat, p_val_anova, \"★\" if p_val_anova<0.05 else \"•\"]\n",
    "], columns=[\"Test\",\"Statistic\",\"p-value\",\"Significance\"])\n",
    "\n",
    "stats_results[\"summary_table\"] = results_table\n",
    "\n",
    "# --- Save to pickle ---\n",
    "PROC_DIR.mkdir(parents=True, exist_ok=True)\n",
    "with open(PROC_DIR / \"stats_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(stats_results, f)\n",
    "\n",
    "print(\"Saved stats_results.pkl in models/\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
